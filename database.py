# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import sqlite3
import json
import logging
import sys
import os
import time
import random
import threading  
from collections import OrderedDict
from datetime import datetime
from functools import wraps
from typing import List, Optional, Dict, Tuple, Any

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ
from models import InterviewRequest, InterviewSlot
from config import Config

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def retry_on_failure(max_retries=3, delay=1):
    """API ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    logger.warning(f"ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}")
                    if attempt == max_retries - 1:
                        logger.error(f"ìµœì¢… ì‹¤íŒ¨: {e}")
                        raise e
                    
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°
                    wait_time = delay * (2 ** attempt) + random.uniform(0, 1)
                    logger.info(f"{wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
            return None
        return wrapper
    return decorator

class DatabaseManager:
    def __init__(self, db_path: str = Config.DATABASE_PATH):
        self.db_path = db_path
        self.gc = None
        self.sheet = None
        
        # âœ… ê°œì„ ëœ ìºì‹œ ì„¤ì •
        self._cache_timeout = 300  # 5ë¶„ìœ¼ë¡œ ë‹¨ì¶• (ê¸°ì¡´ 1000ì´ˆ â†’ 300ì´ˆ)
        self._max_cache_size = 100  # ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜ ì œí•œ
        self._request_cache = OrderedDict()  # LRU ìºì‹œë¥¼ ìœ„í•œ OrderedDict
        self._cache_lock = threading.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._last_cleanup = time.time()
        self._cleanup_interval = 60  # 1ë¶„ë§ˆë‹¤ ìºì‹œ ì •ë¦¬
        
        self.init_database()
        self.init_google_sheet()
        self.migrate_database_schema()

    def _cleanup_expired_cache(self):
        """ë§Œë£Œëœ ìºì‹œ í•­ëª© ì •ë¦¬ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        with self._cache_lock:
            current_time = time.time()
            
            # ì •ë¦¬ ê°„ê²© ì²´í¬
            if current_time - self._last_cleanup < self._cleanup_interval:
                return
            
            # ë§Œë£Œëœ í•­ëª© ì°¾ê¸°
            expired_keys = []
            for key, (cached_data, timestamp) in self._request_cache.items():
                if current_time - timestamp > self._cache_timeout:
                    expired_keys.append(key)
            
            # ë§Œë£Œëœ í•­ëª© ì‚­ì œ
            for key in expired_keys:
                del self._request_cache[key]
            
            # í¬ê¸° ì œí•œ ì ìš© (LRU ë°©ì‹)
            while len(self._request_cache) > self._max_cache_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = next(iter(self._request_cache))
                del self._request_cache[oldest_key]
            
            self._last_cleanup = current_time
            
            if expired_keys:
                logger.info(f"ğŸ§¹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {len(expired_keys)}ê°œ ë§Œë£Œ í•­ëª© ì‚­ì œ")

    def _get_from_cache(self, clean_id: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ì•ˆì „í•˜ê²Œ ì¡°íšŒ"""
        with self._cache_lock:
            current_time = time.time()
            
            if clean_id in self._request_cache:
                cached_data, timestamp = self._request_cache[clean_id]
                
                if current_time - timestamp < self._cache_timeout:
                    # LRU ì—…ë°ì´íŠ¸ (ìµœê·¼ ì‚¬ìš©ëœ í•­ëª©ì„ ë§¨ ë’¤ë¡œ)
                    self._request_cache.move_to_end(clean_id)
                    logger.info(f"ğŸ“„ ìºì‹œ íˆíŠ¸: {clean_id}")
                    return cached_data
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                    del self._request_cache[clean_id]
                    logger.info(f"â° ìºì‹œ ë§Œë£Œ: {clean_id}")
            
            return None

    def _set_to_cache(self, clean_id: str, request_data: Any):
        """ìºì‹œì— ì•ˆì „í•˜ê²Œ ì €ì¥"""
        with self._cache_lock:
            current_time = time.time()
            
            # ìºì‹œ í¬ê¸° ì œí•œ ì²´í¬
            if len(self._request_cache) >= self._max_cache_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = next(iter(self._request_cache))
                del self._request_cache[oldest_key]
                logger.info(f"ğŸ—‘ï¸ ìºì‹œ í¬ê¸° ì œí•œìœ¼ë¡œ ì œê±°: {oldest_key}")
            
            # ìƒˆ ë°ì´í„° ì €ì¥
            self._request_cache[clean_id] = (request_data, current_time)
            logger.info(f"ğŸ’¾ ìºì‹œ ì €ì¥: {clean_id} (ì´ {len(self._request_cache)}ê°œ)")

    def migrate_database_schema(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # í˜„ì¬ í…Œì´ë¸” êµ¬ì¡° í™•ì¸
                cursor.execute("PRAGMA table_info(interview_requests)")
                columns = [column[1] for column in cursor.fetchall()]
                
                logger.info(f"í˜„ì¬ í…Œì´ë¸” ì»¬ëŸ¼: {columns}")
                
                # detailed_position_name ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
                if 'detailed_position_name' not in columns:
                    cursor.execute("""
                        ALTER TABLE interview_requests 
                        ADD COLUMN detailed_position_name TEXT DEFAULT ''
                    """)
                    logger.info("âœ… detailed_position_name ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
                
                # candidate_phone ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
                if 'candidate_phone' not in columns:
                    cursor.execute("""
                        ALTER TABLE interview_requests 
                        ADD COLUMN candidate_phone TEXT DEFAULT ''
                    """)
                    logger.info("âœ… candidate_phone ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
                
                conn.commit()
                logger.info("ğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ê¸°ì¡´ í…Œì´ë¸”
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS interview_requests (
                        id TEXT PRIMARY KEY,
                        interviewer_id TEXT NOT NULL,
                        candidate_email TEXT NOT NULL,
                        candidate_name TEXT NOT NULL,
                        position_name TEXT NOT NULL,
                        detailed_position_name TEXT,
                        status TEXT NOT NULL,
                        created_at TIMESTAMP,
                        updated_at TIMESTAMP,
                        available_slots TEXT,
                        preferred_datetime_slots TEXT,
                        selected_slot TEXT,
                        candidate_note TEXT,
                        candidate_phone TEXT
                    )
                """)

                # âœ… ê¸°ì¡´ í…Œì´ë¸”ì— ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜)
                try:
                    conn.execute("ALTER TABLE interview_requests ADD COLUMN detailed_position_name TEXT")
                    logger.info("âœ… detailed_position_name ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
                except Exception as e:
                    if "duplicate column name" not in str(e).lower():
                        logger.warning(f"detailed_position_name ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„: {e}")
                
                try:
                    conn.execute("ALTER TABLE interview_requests ADD COLUMN candidate_phone TEXT")
                    logger.info("âœ… candidate_phone ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
                except Exception as e:
                    if "duplicate column name" not in str(e).lower():
                        logger.warning(f"candidate_phone ì»¬ëŸ¼ ì¶”ê°€ ì‹œë„: {e}")
                
                # âœ… ë©´ì ‘ê´€ ì‘ë‹µ í…Œì´ë¸” ì¶”ê°€
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS interviewer_responses (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        request_id TEXT NOT NULL,
                        interviewer_id TEXT NOT NULL,
                        available_slots TEXT NOT NULL,
                        responded_at TIMESTAMP,
                        UNIQUE(request_id, interviewer_id)
                    )
                """)
                
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    @retry_on_failure(max_retries=3, delay=2)
    def init_google_sheet(self):
        """êµ¬ê¸€ ì‹œíŠ¸ ì´ˆê¸°í™”"""
        try:
            scope = [
                'https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive'
            ]
            
            service_account_info = None
            
            # ë°©ë²• 1: Streamlit Secrets (TOML êµ¬ì¡°)
            try:
                if hasattr(st, 'secrets') and "google_credentials" in st.secrets:
                    logger.info("ğŸ” TOML êµ¬ì¡°ë¡œ Secrets ì½ê¸° ì‹œë„...")
                    
                    private_key = st.secrets["google_credentials"]["private_key"]
                    
                    if "\\n" in private_key:
                        private_key = private_key.replace("\\n", "\n")
                    
                    private_key = private_key.strip()
                    lines = private_key.split('\n')
                    cleaned_lines = [line.strip() for line in lines if line.strip()]
                    private_key = '\n'.join(cleaned_lines)
                    
                    service_account_info = {
                        "type": st.secrets["google_credentials"]["type"],
                        "project_id": st.secrets["google_credentials"]["project_id"],
                        "private_key_id": st.secrets["google_credentials"]["private_key_id"],
                        "private_key": private_key,
                        "client_email": st.secrets["google_credentials"]["client_email"],
                        "client_id": st.secrets["google_credentials"]["client_id"],
                        "auth_uri": st.secrets["google_credentials"]["auth_uri"],
                        "token_uri": st.secrets["google_credentials"]["token_uri"],
                        "auth_provider_x509_cert_url": st.secrets["google_credentials"]["auth_provider_x509_cert_url"],
                        "client_x509_cert_url": st.secrets["google_credentials"]["client_x509_cert_url"],
                        "universe_domain": st.secrets["google_credentials"]["universe_domain"]
                    }
                    logger.info("âœ… Streamlit Secretsì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ")
                    
            except Exception as e:
                logger.warning(f"TOML Secrets ì½ê¸° ì‹¤íŒ¨: {e}")
            
            if not service_account_info:
                logger.error("âŒ ì¸ì¦ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                self.gc = None
                self.sheet = None
                return
            
            # Google ì¸ì¦
            try:
                import tempfile
                
                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
                    json.dump(service_account_info, temp_file)
                    temp_path = temp_file.name
                
                credentials = Credentials.from_service_account_file(temp_path, scopes=scope)
                os.unlink(temp_path)
                
                logger.info("âœ… Google ì¸ì¦ ì„±ê³µ")
                
            except Exception as e:
                logger.error(f"âŒ Google ì¸ì¦ ì‹¤íŒ¨: {e}")
                raise
            
            self.gc = gspread.authorize(credentials)
            
            sheet_id = st.secrets["GOOGLE_SHEET_ID"]
            self.sheet = self.gc.open_by_key(sheet_id).sheet1
            logger.info("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
            
            # í—¤ë” ì„¤ì •
            headers = [
                "ìš”ì²­ID", "ìƒì„±ì¼ì‹œ", "ê³µê³ ëª…", "ìƒì„¸ê³µê³ ëª…",
                "ë©´ì ‘ê´€ID", "ë©´ì ‘ê´€ì´ë¦„", "ë©´ì ‘ìëª…", 
                "ë©´ì ‘ìì´ë©”ì¼", "ë©´ì ‘ìì „í™”ë²ˆí˜¸", 
                "ìƒíƒœ", "ìƒíƒœë³€ê²½ì¼ì‹œ", "ì¸ì‚¬íŒ€ì œì•ˆì¼ì‹œ", "ë©´ì ‘ê´€í™•ì •ì¼ì‹œ",  # âœ… ë³€ê²½
                "ë©´ì ‘ìí™•ì •ì¼ì‹œ", "ë©´ì ‘ììš”ì²­ì‚¬í•­", "ë§ˆì§€ë§‰ì—…ë°ì´íŠ¸", "ì²˜ë¦¬ì†Œìš”ì‹œê°„", "ë¹„ê³ "  # âœ… ë³€ê²½
            ]
            
            try:
                existing_headers = self.sheet.row_values(1)
                
                if not existing_headers or "ë©´ì ‘ìí™•ì •ì¼ì‹œ" not in existing_headers:  # âœ… ë³€ê²½
                    self._setup_sheet_headers(headers)
                else:
                    logger.info("êµ¬ê¸€ì‹œíŠ¸ í—¤ë” ì´ë¯¸ ì¡´ì¬í•¨")
                    
            except Exception as e:
                self._setup_sheet_headers(headers)
                
            logger.info("ğŸ‰ êµ¬ê¸€ ì‹œíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
                
        except Exception as e:
            logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gc = None
            self.sheet = None
    
    def _setup_sheet_headers(self, headers):
        """ì‹œíŠ¸ í—¤ë” ì„¤ì •"""
        try:
            if "ìƒì„¸ê³µê³ ëª…" not in headers:
                headers.insert(3, "ìƒì„¸ê³µê³ ëª…")
            
            self.sheet.clear()
            self.sheet.append_row(headers)
            
            self.sheet.format('1:1', {
                'backgroundColor': {'red': 0.2, 'green': 0.6, 'blue': 0.9},
                'textFormat': {
                    'bold': True, 
                    'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}
                }
            })
            logger.info("ì‹œíŠ¸ í—¤ë” ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í—¤ë” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def save_interview_request(self, request: InterviewRequest):
        """ë©´ì ‘ ìš”ì²­ ì €ì¥"""
        try:
            from utils import normalize_request_id  # âœ… ì¶”ê°€
            
            # âœ… ID ì •ê·œí™”
            normalized_id = normalize_request_id(request.id)
            
            detailed_name = getattr(request, 'detailed_position_name', '')
            phone = getattr(request, 'candidate_phone', '')
            
            logger.info(f"ğŸ’¾ DB ì €ì¥ ì‹œë„")
            logger.info(f"  - ì›ë³¸ ID: {request.id}")
            logger.info(f"  - ì •ê·œí™” ID: {normalized_id}")
            logger.info(f"  - ê³µê³ ëª…: {request.position_name}")
            logger.info(f"  - ìƒì„¸ê³µê³ ëª…: '{detailed_name}'")
            logger.info(f"  - ì „í™”ë²ˆí˜¸: '{phone}'")
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO interview_requests 
                    (id, interviewer_id, candidate_email, candidate_name, position_name, 
                    detailed_position_name, status, created_at, updated_at, available_slots, 
                    preferred_datetime_slots, selected_slot, candidate_note, candidate_phone)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    normalized_id,  # âœ… ì •ê·œí™”ëœ ID ì €ì¥
                    request.interviewer_id,
                    request.candidate_email,
                    request.candidate_name,
                    request.position_name,
                    detailed_name,
                    request.status,
                    request.created_at.isoformat(),
                    (request.updated_at or datetime.now()).isoformat(),
                    json.dumps([{"date": slot.date, "time": slot.time, "duration": slot.duration} 
                            for slot in request.available_slots]),
                    json.dumps(request.preferred_datetime_slots) if request.preferred_datetime_slots else None,
                    json.dumps({"date": request.selected_slot.date, "time": request.selected_slot.time, 
                            "duration": request.selected_slot.duration}) if request.selected_slot else None,
                    request.candidate_note or "",
                    phone
                ))
                logger.info(f"âœ… ë©´ì ‘ ìš”ì²­ ì €ì¥ ì™„ë£Œ: {normalized_id}")
            
            try:
                self.update_google_sheet(request)
            except Exception as e:
                logger.warning(f"êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            logger.error(f"ë©´ì ‘ ìš”ì²­ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_interviewer_response(self, request_id: str, interviewer_id: str, slots: List[InterviewSlot]):
        """ê°œë³„ ë©´ì ‘ê´€ì˜ ì¼ì • ì‘ë‹µ ì €ì¥"""
        try:
            slots_json = json.dumps([
                {"date": slot.date, "time": slot.time, "duration": slot.duration} 
                for slot in slots
            ])
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO interviewer_responses 
                    (request_id, interviewer_id, available_slots, responded_at)
                    VALUES (?, ?, ?, ?)
                """, (
                    request_id,
                    interviewer_id,
                    slots_json,
                    datetime.now().isoformat()
                ))
                
            logger.info(f"ë©´ì ‘ê´€ {interviewer_id} ì‘ë‹µ ì €ì¥ ì™„ë£Œ: {len(slots)}ê°œ ìŠ¬ë¡¯")
            return True
            
        except Exception as e:
            logger.error(f"ë©´ì ‘ê´€ ì‘ë‹µ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def get_interviewer_responses(self, request_id: str) -> dict:
        """íŠ¹ì • ìš”ì²­ì— ëŒ€í•œ ëª¨ë“  ë©´ì ‘ê´€ì˜ ì‘ë‹µ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(
                    "SELECT interviewer_id, available_slots, responded_at FROM interviewer_responses WHERE request_id = ?",
                    (request_id,)
                )
                rows = cursor.fetchall()
            
            responses = {}
            for row in rows:
                interviewer_id = row[0]
                try:
                    slots_data = json.loads(row[1])
                    slots = [InterviewSlot(**slot) for slot in slots_data]
                    responses[interviewer_id] = slots
                    logger.info(f"ë©´ì ‘ê´€ {interviewer_id} ì‘ë‹µ ë¡œë“œ: {len(slots)}ê°œ ìŠ¬ë¡¯")
                except json.JSONDecodeError as e:
                    logger.warning(f"ë©´ì ‘ê´€ {interviewer_id} ìŠ¬ë¡¯ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"ì´ {len(responses)}ëª…ì˜ ë©´ì ‘ê´€ ì‘ë‹µ ì¡°íšŒ ì™„ë£Œ (request_id: {request_id[:8]}...)")
            return responses
            
        except Exception as e:
            logger.error(f"ë©´ì ‘ê´€ ì‘ë‹µ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def check_all_interviewers_responded(self, request: InterviewRequest) -> Tuple[bool, int, int]:
        """ëª¨ë“  ë©´ì ‘ê´€ì´ ì¼ì •ì„ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸ (ìˆ˜ì •ëœ ë²„ì „)"""
        try:
            interviewer_ids = [id.strip() for id in request.interviewer_id.split(',')]
            total_count = len(interviewer_ids)
            
            logger.info(f"ğŸ” ë©´ì ‘ê´€ ì‘ë‹µ í™•ì¸ ì‹œì‘: {total_count}ëª… ë©´ì ‘ê´€")
            logger.info(f"  - ë©´ì ‘ê´€ ID: {interviewer_ids}")
            logger.info(f"  - available_slots ìˆ˜: {len(request.available_slots) if request.available_slots else 0}")
            
            # âœ… ë‹¨ì¼ ë©´ì ‘ê´€ì¸ ê²½ìš°
            if total_count == 1:
                has_slots = request.available_slots and len(request.available_slots) > 0
                responded_count = 1 if has_slots else 0
                logger.info(f"ë‹¨ì¼ ë©´ì ‘ê´€ ì‘ë‹µ í™•ì¸: {responded_count}/{total_count}")
                return (has_slots, responded_count, total_count)
            
            # âœ… ë³µìˆ˜ ë©´ì ‘ê´€ì¸ ê²½ìš° - ë¡œì§ ê°œì„ 
            # 1ì°¨: available_slotsì´ ìˆìœ¼ë©´ ëª¨ë“  ë©´ì ‘ê´€ì´ ì‘ë‹µí–ˆë‹¤ê³  ê°„ì£¼
            if request.available_slots and len(request.available_slots) > 0:
                logger.info(f"âœ… available_slots ì¡´ì¬ â†’ ëª¨ë“  ë©´ì ‘ê´€ ì‘ë‹µ ì™„ë£Œë¡œ ê°„ì£¼")
                return (True, total_count, total_count)
            
            # 2ì°¨: interviewer_responses í…Œì´ë¸” í™•ì¸
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(
                    "SELECT COUNT(DISTINCT interviewer_id) FROM interviewer_responses WHERE request_id = ?",
                    (request.id,)
                )
                result = cursor.fetchone()
                responded_count = result[0] if result else 0
            
            logger.info(f"interviewer_responses í…Œì´ë¸” í™•ì¸: {responded_count}/{total_count}")
            
            # 3ì°¨: available_slotsì´ ì—†ê³  ê°œë³„ ì‘ë‹µë„ ë¶€ì¡±í•œ ê²½ìš°
            all_responded = (responded_count == total_count)
            return (all_responded, responded_count, total_count)
                
        except Exception as e:
            logger.error(f"ë©´ì ‘ê´€ ì‘ë‹µ í™•ì¸ ì‹¤íŒ¨: {e}")
            try:
                interviewer_count = len(request.interviewer_id.split(','))
            except Exception:
                interviewer_count = 1
            return (False, 0, interviewer_count)
        
    def sync_from_google_sheet_to_db(self):
        """êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ SQLite DBë¡œ ë™ê¸°í™”"""
        try:
            if not self.sheet:
                logger.warning("êµ¬ê¸€ ì‹œíŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
            
            # êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            all_records = self.sheet.get_all_records()
            
            for record in all_records:
                try:
                    # êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ InterviewRequest ê°ì²´ë¡œ ë³€í™˜
                    request_id = record.get('ìš”ì²­ID', '')
                    if not request_id:
                        continue
                    
                    # ì´ë¯¸ DBì— ìˆëŠ”ì§€ í™•ì¸
                    existing = self.get_interview_request(request_id)
                    if existing:
                        logger.info(f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ìš”ì²­ ê±´ë„ˆëœ€: {request_id}")
                        continue
                    
                    # InterviewRequest ê°ì²´ ìƒì„±
                    from models import InterviewRequest, InterviewSlot
                    
                    # available_slots íŒŒì‹±
                    available_slots = []
                    proposed_slots_str = record.get('ì œì•ˆì¼ì‹œëª©ë¡', '')
                    if proposed_slots_str:
                        from utils import parse_proposed_slots
                        slot_data = parse_proposed_slots(proposed_slots_str)
                        available_slots = [InterviewSlot(**slot) for slot in slot_data]
                    
                    # preferred_datetime_slots íŒŒì‹±
                    preferred_slots = []
                    preferred_str = record.get('í¬ë§ì¼ì‹œëª©ë¡', '')
                    if preferred_str:
                        preferred_slots = [slot.strip() for slot in preferred_str.split('|')]
                    
                    # selected_slot íŒŒì‹±
                    selected_slot = None
                    confirmed_str = record.get('í™•ì •ì¼ì‹œ', '')
                    if confirmed_str:
                        # "2025-01-15 14:00(30ë¶„)" í˜•ì‹ íŒŒì‹±
                        import re
                        match = re.match(r'(\d{4}-\d{2}-\d{2})\s+(\d{2}:\d{2})\$(\d+)ë¶„\$', confirmed_str)
                        if match:
                            selected_slot = InterviewSlot(
                                date=match.group(1),
                                time=match.group(2),
                                duration=int(match.group(3))
                            )
                    
                    # ìƒì„±ì¼ì‹œ íŒŒì‹±
                    created_at = datetime.now()
                    created_str = record.get('ìƒì„±ì¼ì‹œ', '')
                    if created_str:
                        try:
                            created_at = datetime.strptime(created_str, '%Y-%m-%d %H:%M')
                        except:
                            pass
                    
                    # ìƒíƒœ ë§¤í•‘
                    status_map = {
                        'ë©´ì ‘ê´€_ì¼ì •ì…ë ¥ëŒ€ê¸°': Config.Status.PENDING_INTERVIEWER,
                        'ë©´ì ‘ì_ì„ íƒëŒ€ê¸°': Config.Status.PENDING_CANDIDATE,
                        'í™•ì •ì™„ë£Œ': Config.Status.CONFIRMED,
                        'ì¼ì •ì¬ì¡°ìœ¨ìš”ì²­': Config.Status.PENDING_CONFIRMATION,
                        'ì·¨ì†Œ': Config.Status.CANCELLED
                    }
                    
                    status = status_map.get(record.get('ìƒíƒœ', ''), Config.Status.PENDING_INTERVIEWER)
                    
                    # InterviewRequest ê°ì²´ ìƒì„±
                    request = InterviewRequest(
                        id=request_id,
                        interviewer_id=record.get('ë©´ì ‘ê´€ID', ''),
                        candidate_email=record.get('ë©´ì ‘ìì´ë©”ì¼', ''),
                        candidate_name=record.get('ë©´ì ‘ìëª…', ''),
                        position_name=record.get('ê³µê³ ëª…', ''),
                        status=status,
                        created_at=created_at,
                        updated_at=datetime.now(),
                        available_slots=available_slots,
                        preferred_datetime_slots=preferred_slots,
                        selected_slot=selected_slot,
                        candidate_note=record.get('ë©´ì ‘ììš”ì²­ì‚¬í•­', '')
                    )
                    
                    # SQLiteì— ì €ì¥ (êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸ëŠ” í•˜ì§€ ì•ŠìŒ)
                    with sqlite3.connect(self.db_path) as conn:
                        conn.execute("""
                            INSERT OR REPLACE INTO interview_requests 
                            (id, interviewer_id, candidate_email, candidate_name, position_name, 
                            status, created_at, updated_at, available_slots, preferred_datetime_slots, 
                            selected_slot, candidate_note)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            request.id,
                            request.interviewer_id,
                            request.candidate_email,
                            request.candidate_name,
                            request.position_name,
                            request.status,
                            request.created_at.isoformat(),
                            request.updated_at.isoformat(),
                            json.dumps([{"date": slot.date, "time": slot.time, "duration": slot.duration} 
                                    for slot in request.available_slots]),
                            json.dumps(request.preferred_datetime_slots) if request.preferred_datetime_slots else None,
                            json.dumps({"date": request.selected_slot.date, "time": request.selected_slot.time, 
                                    "duration": request.selected_slot.duration}) if request.selected_slot else None,
                            request.candidate_note or ""
                        ))
                    
                    logger.info(f"êµ¬ê¸€ì‹œíŠ¸ â†’ DB ë™ê¸°í™” ì™„ë£Œ: {request_id}")
                    
                except Exception as e:
                    logger.error(f"ë ˆì½”ë“œ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info("êµ¬ê¸€ì‹œíŠ¸ â†’ SQLite DB ë™ê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def get_common_available_slots(self, request: InterviewRequest) -> List[InterviewSlot]:
        """ëª¨ë“  ë©´ì ‘ê´€ì´ ê³µí†µìœ¼ë¡œ ì„ íƒí•œ 30ë¶„ ë‹¨ìœ„ íƒ€ì„ìŠ¬ë¡¯ ë°˜í™˜"""
        try:
            interviewer_ids = [id.strip() for id in request.interviewer_id.split(',')]
            
            # ë‹¨ì¼ ë©´ì ‘ê´€ì¸ ê²½ìš°
            if len(interviewer_ids) == 1:
                return request.available_slots
            
            # ë³µìˆ˜ ë©´ì ‘ê´€ì¸ ê²½ìš°
            responses = self.get_interviewer_responses(request.id)
            
            if len(responses) < len(interviewer_ids):
                logger.warning(f"ì¼ë¶€ ë©´ì ‘ê´€ì´ ì•„ì§ ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {len(responses)}/{len(interviewer_ids)}")
                return []
            
            # ê° ë©´ì ‘ê´€ë³„ íƒ€ì„ìŠ¬ë¡¯ì„ setìœ¼ë¡œ ë³€í™˜
            slot_sets = []
            for interviewer_id in interviewer_ids:
                if interviewer_id in responses:
                    slot_keys = set()
                    for slot in responses[interviewer_id]:
                        key = f"{slot.date}_{slot.time}"
                        slot_keys.add(key)
                    slot_sets.append(slot_keys)
                else:
                    logger.warning(f"ë©´ì ‘ê´€ {interviewer_id}ì˜ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                    return []
            
            # êµì§‘í•© ê³„ì‚°
            if not slot_sets:
                return []
            
            common_slot_keys = set.intersection(*slot_sets)
            
            # í‚¤ë¥¼ ë‹¤ì‹œ InterviewSlot ê°ì²´ë¡œ ë³€í™˜
            common_slots = []
            for key in common_slot_keys:
                date_part, time_part = key.split('_')
                common_slots.append(InterviewSlot(
                    date=date_part,
                    time=time_part,
                    duration=30
                ))
            
            # ë‚ ì§œ/ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
            common_slots.sort(key=lambda x: (x.date, x.time))
            
            logger.info(f"ê³µí†µ íƒ€ì„ìŠ¬ë¡¯ {len(common_slots)}ê°œ ë°œê²¬: {request.position_name}")
            return common_slots
            
        except Exception as e:
            logger.error(f"ê³µí†µ íƒ€ì„ìŠ¬ë¡¯ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def find_overlapping_time_slots(self, request: InterviewRequest) -> List[InterviewSlot]:
        """ëª¨ë“  ë©´ì ‘ê´€ì´ ê³µí†µìœ¼ë¡œ ê°€ëŠ¥í•œ 30ë¶„ ë‹¨ìœ„ íƒ€ì„ìŠ¬ë¡¯ ì°¾ê¸°"""
        try:
            interviewer_ids = [id.strip() for id in request.interviewer_id.split(',')]
            
            # ë‹¨ì¼ ë©´ì ‘ê´€ì¸ ê²½ìš°
            if len(interviewer_ids) == 1:
                return request.available_slots
            
            # ë³µìˆ˜ ë©´ì ‘ê´€ì¸ ê²½ìš° - get_common_available_slots ì¬ì‚¬ìš©
            return self.get_common_available_slots(request)
            
        except Exception as e:
            logger.error(f"ì¤‘ë³µ íƒ€ì„ìŠ¬ë¡¯ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def get_available_slots_for_candidate(self, request: InterviewRequest) -> List[InterviewSlot]:
        """ë©´ì ‘ìê°€ ì„ íƒ ê°€ëŠ¥í•œ 30ë¶„ ë‹¨ìœ„ íƒ€ì„ìŠ¬ë¡¯ ì¡°íšŒ (ì´ë¯¸ ì˜ˆì•½ëœ ìŠ¬ë¡¯ ì œì™¸)"""
        try:
            # 1. ì¤‘ë³µ íƒ€ì„ìŠ¬ë¡¯ ê°€ì ¸ì˜¤ê¸°
            all_slots = self.find_overlapping_time_slots(request)
            
            # 2. ë™ì¼ í¬ì§€ì…˜ì˜ í™•ì •ëœ íƒ€ì„ìŠ¬ë¡¯ ê°€ì ¸ì˜¤ê¸°
            all_requests = self.get_all_requests()
            reserved_slot_keys = set()
            
            for req in all_requests:
                if (req.position_name == request.position_name 
                    and req.status == Config.Status.CONFIRMED 
                    and req.selected_slot 
                    and req.id != request.id):
                    
                    key = f"{req.selected_slot.date}_{req.selected_slot.time}"
                    reserved_slot_keys.add(key)
            
            # 3. ì˜ˆì•½ë˜ì§€ ì•Šì€ íƒ€ì„ìŠ¬ë¡¯ë§Œ í•„í„°ë§
            available_slots = []
            for slot in all_slots:
                key = f"{slot.date}_{slot.time}"
                if key not in reserved_slot_keys:
                    available_slots.append(slot)
            
            logger.info(f"ì„ íƒ ê°€ëŠ¥í•œ íƒ€ì„ìŠ¬ë¡¯ {len(available_slots)}ê°œ (ì˜ˆì•½ë¨: {len(reserved_slot_keys)}ê°œ)")
            return available_slots
            
        except Exception as e:
            logger.error(f"ì„ íƒ ê°€ëŠ¥í•œ íƒ€ì„ìŠ¬ë¡¯ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def reserve_slot_for_candidate(self, request: InterviewRequest, selected_slot: InterviewSlot) -> bool:
        """ë©´ì ‘ìê°€ ì„ íƒí•œ 30ë¶„ íƒ€ì„ìŠ¬ë¡¯ ì˜ˆì•½ (ì¤‘ë³µ ì˜ˆì•½ ë°©ì§€)"""
        try:
            # 1. í•´ë‹¹ íƒ€ì„ìŠ¬ë¡¯ì´ ì´ë¯¸ ì˜ˆì•½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            all_requests = self.get_all_requests()
            
            for req in all_requests:
                if (req.position_name == request.position_name 
                    and req.status == Config.Status.CONFIRMED 
                    and req.selected_slot 
                    and req.id != request.id):
                    
                    if (req.selected_slot.date == selected_slot.date 
                        and req.selected_slot.time == selected_slot.time):
                        logger.warning(f"íƒ€ì„ìŠ¬ë¡¯ ì¤‘ë³µ ì˜ˆì•½ ì‹œë„: {selected_slot.date} {selected_slot.time}")
                        return False
            
            # 2. ì˜ˆì•½ ê°€ëŠ¥ - ìš”ì²­ ì—…ë°ì´íŠ¸
            request.selected_slot = selected_slot
            request.status = Config.Status.CONFIRMED
            request.updated_at = datetime.now()
            
            self.save_interview_request(request)
            self.update_google_sheet(request)
            
            logger.info(f"íƒ€ì„ìŠ¬ë¡¯ ì˜ˆì•½ ì„±ê³µ: {selected_slot.date} {selected_slot.time}")
            return True
            
        except Exception as e:
            logger.error(f"íƒ€ì„ìŠ¬ë¡¯ ì˜ˆì•½ ì‹¤íŒ¨: {e}")
            return False
    
    def get_interview_request(self, request_id: str) -> Optional[InterviewRequest]:
        from utils import normalize_request_id
        
        try:
            clean_id = normalize_request_id(request_id)
            current_time = time.time()  # â† ì´ ì¤„ ì¶”ê°€
            
            # ìºì‹œ ì •ë¦¬ (ì£¼ê¸°ì )
            self._cleanup_expired_cache()
            
            # ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
            cached_request = self._get_from_cache(clean_id)
            if cached_request is not None:
                return cached_request
            
            logger.info(f"ğŸ” DB ì¡°íšŒ ì‹œì‘: {clean_id}")
            
            # SQLiteì—ì„œ ì¡°íšŒ
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("SELECT * FROM interview_requests WHERE id = ?", (clean_id,))
                row = cursor.fetchone()
                
                if row:
                    logger.info(f"âœ… SQLiteì—ì„œ ë°œê²¬: {clean_id}")
                    request = self._row_to_request(row)
                    
                    # âœ… ìºì‹œì— ì €ì¥ (í˜„ì¬ ì‹œê°„ê³¼ í•¨ê»˜)
                    if request:
                        current_time = time.time()
                        self._set_to_cache(clean_id, request)
                    
                    return request
            
            # êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ì¡°íšŒ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ)
            logger.warning(f"âš ï¸ SQLiteì—ì„œ ëª» ì°¾ìŒ: {clean_id}")
            
            if not self.sheet:
                logger.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì—†ìŒ")
                return None
            
            try:
                records = self.sheet.get_all_records()
                logger.info(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ë ˆì½”ë“œ ìˆ˜: {len(records)}")
                
                for i, record in enumerate(records):
                    sheet_id = normalize_request_id(record.get('ìš”ì²­ID', ''))
                    if sheet_id == clean_id:
                        logger.info(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ìš”ì²­ ë°œê²¬: {clean_id} (í–‰: {i+2})")
                        
                        # êµ¬ê¸€ ì‹œíŠ¸ â†’ InterviewRequest ë³€í™˜
                        request = self._convert_sheet_record_to_request(record)
                        if request:
                            # SQLiteì™€ ë™ê¸°í™”
                            self.save_interview_request(request)
                            
                            # âœ… ìºì‹œì—ë„ ì €ì¥ (ì¶”ê°€ëœ ë¶€ë¶„!)
                            self._set_to_cache(clean_id, request)
                            
                            logger.info(f"ğŸ”„ êµ¬ê¸€ì‹œíŠ¸ â†’ SQLite ë™ê¸°í™” ì™„ë£Œ: {clean_id}")
                            return request
                
                logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œë„ ìš”ì²­ì„ ì°¾ì§€ ëª»í•¨: {clean_id}")
                
                # ë””ë²„ê¹…: êµ¬ê¸€ì‹œíŠ¸ ë‚´ ëª¨ë“  ìš”ì²­ID ì¶œë ¥
                all_ids = [normalize_request_id(r.get('ìš”ì²­ID', '')) for r in records[:10]]
                logger.info(f"ğŸ” êµ¬ê¸€ì‹œíŠ¸ ìƒ˜í”Œ IDë“¤: {all_ids}")
                
            except Exception as sheet_error:
                logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {sheet_error}")
                
            return None
            
        except Exception as e:
            logger.error(f"âŒ ìš”ì²­ ì¡°íšŒ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def clear_cache(self):
        """ìºì‹œ ì™„ì „ ì´ˆê¸°í™”"""
        with self._cache_lock:
            cleared_count = len(self._request_cache)
            self._request_cache.clear()
            logger.info(f"ğŸ§½ ìºì‹œ ì™„ì „ ì´ˆê¸°í™”: {cleared_count}ê°œ í•­ëª© ì‚­ì œ")

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´"""
        with self._cache_lock:
            current_time = time.time()
            active_count = 0
            expired_count = 0
            
            for _, (cached_data, timestamp) in self._request_cache.items():
                if current_time - timestamp < self._cache_timeout:
                    active_count += 1
                else:
                    expired_count += 1
            
            return {
                'total_items': len(self._request_cache),
                'active_items': active_count,
                'expired_items': expired_count,
                'cache_timeout': self._cache_timeout,
                'max_cache_size': self._max_cache_size,
                'last_cleanup': datetime.fromtimestamp(self._last_cleanup).isoformat()
            }

    def _row_to_request(self, row) -> Optional[InterviewRequest]:
        """SQLite í–‰ì„ InterviewRequest ê°ì²´ë¡œ ë³€í™˜ (í˜¸í™˜ì„± ë³´ì¥)"""
        try:
            # ì»¬ëŸ¼ ìˆ˜ì— ë”°ë¥¸ í˜¸í™˜ì„± ì²˜ë¦¬
            if len(row) == 12:  # ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ
                row = list(row) + ["", ""]  # detailed_position_name, candidate_phone ì¶”ê°€
            elif len(row) != 14:  # ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìŠ¤í‚¤ë§ˆ
                logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìŠ¤í‚¤ë§ˆ: {len(row)}ê°œ ì»¬ëŸ¼")
                return None

            # JSON íŒŒì‹±
            available_slots = []
            if row[9]:
                try:
                    slots_data = json.loads(row[9])
                    available_slots = [InterviewSlot(**slot) for slot in slots_data]
                except json.JSONDecodeError as e:
                    logger.warning(f"available_slots íŒŒì‹± ì‹¤íŒ¨: {e}")

            preferred_datetime_slots = []
            if row[10]:
                try:
                    preferred_datetime_slots = json.loads(row[10])
                except json.JSONDecodeError as e:
                    logger.warning(f"preferred_datetime_slots íŒŒì‹± ì‹¤íŒ¨: {e}")

            selected_slot = None
            if row[11]:
                try:
                    slot_data = json.loads(row[11])
                    selected_slot = InterviewSlot(**slot_data)
                except json.JSONDecodeError as e:
                    logger.warning(f"selected_slot íŒŒì‹± ì‹¤íŒ¨: {e}")

            return InterviewRequest(
                id=row[0],
                interviewer_id=row[1],
                candidate_email=row[2],
                candidate_name=row[3],
                position_name=row[4],
                detailed_position_name=row[5] or "",
                status=row[6],
                created_at=datetime.fromisoformat(row[7]),
                updated_at=datetime.fromisoformat(row[8]) if row[8] else None,
                available_slots=available_slots,
                preferred_datetime_slots=preferred_datetime_slots,
                selected_slot=selected_slot,
                candidate_note=row[12] or "",
                candidate_phone=row[13] or ""
            )
            
        except Exception as e:
            logger.error(f"âŒ í–‰ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def _convert_sheet_record_to_request(self, record: dict) -> Optional[InterviewRequest]:
        """êµ¬ê¸€ ì‹œíŠ¸ ë ˆì½”ë“œë¥¼ InterviewRequest ê°ì²´ë¡œ ë³€í™˜ (ê°•í™”)"""
        try:
            from utils import normalize_request_id
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['ìš”ì²­ID', 'ë©´ì ‘ê´€ID', 'ë©´ì ‘ìëª…', 'ë©´ì ‘ìì´ë©”ì¼', 'ê³µê³ ëª…']
            missing_fields = []
            
            for field in required_fields:
                if not str(record.get(field, '')).strip():
                    missing_fields.append(field)
            
            if missing_fields:
                logger.warning(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing_fields}")
                return None

            # ì œì•ˆ ì¼ì‹œ ëª©ë¡ íŒŒì‹±
            preferred_slots = []
            preferred_str = record.get('ì¸ì‚¬íŒ€ì œì•ˆì¼ì‹œ', '')  # âœ… ë³€ê²½
            if preferred_str:
                preferred_slots = [slot.strip() for slot in preferred_str.split('|') if slot.strip()]

            # ì œì•ˆ ìŠ¬ë¡¯ íŒŒì‹±
            available_slots = []
            proposed_str = record.get('ë©´ì ‘ê´€í™•ì •ì¼ì‹œ', '')  # âœ… ë³€ê²½
            if proposed_str:
                from utils import parse_proposed_slots
                try:
                    slot_data = parse_proposed_slots(proposed_str)
                    available_slots = [InterviewSlot(**slot) for slot in slot_data]
                except Exception as slot_error:
                    logger.warning(f"ì œì•ˆìŠ¬ë¡¯ íŒŒì‹± ì‹¤íŒ¨: {slot_error}")

            # í™•ì • ìŠ¬ë¡¯ íŒŒì‹±
            selected_slot = None
            confirmed_str = record.get('ë©´ì ‘ìí™•ì •ì¼ì‹œ', '')
            if confirmed_str:
                try:
                    import re
                    # "2025-01-15 14:00(30ë¶„)" í˜•ì‹ íŒŒì‹±
                    match = re.match(r'(\d{4}-\d{2}-\d{2})\s+(\d{2}:\d{2})$(\d+)ë¶„$', confirmed_str)
                    if match:
                        selected_slot = InterviewSlot(
                            date=match.group(1),
                            time=match.group(2),
                            duration=int(match.group(3))
                        )
                except Exception as slot_error:
                    logger.warning(f"í™•ì •ìŠ¬ë¡¯ íŒŒì‹± ì‹¤íŒ¨: {slot_error}")

            # ìƒì„±ì¼ì‹œ íŒŒì‹±
            created_at = datetime.now()
            created_str = record.get('ìƒì„±ì¼ì‹œ', '')
            if created_str:
                try:
                    created_at = datetime.strptime(created_str, '%Y-%m-%d %H:%M')
                except ValueError:
                    try:
                        created_at = datetime.fromisoformat(created_str.replace(' ', 'T'))
                    except:
                        pass

            # ìƒíƒœ ë§¤í•‘
            status_map = {
                'ë©´ì ‘ê´€_ì¼ì •ëŒ€ê¸°': Config.Status.PENDING_INTERVIEWER,
                'ë©´ì ‘ì_ì„ íƒëŒ€ê¸°': Config.Status.PENDING_CANDIDATE,
                'ë©´ì ‘ì_ë©”ì¼ë°œì†¡': Config.Status.CANDIDATE_EMAIL_SENT,
                'í™•ì •ì™„ë£Œ': Config.Status.CONFIRMED,
                'ì¼ì •ì¬ì¡°ìœ¨ìš”ì²­': Config.Status.PENDING_CONFIRMATION,
                'ì·¨ì†Œ': Config.Status.CANCELLED
            }
            
            status = status_map.get(record.get('ìƒíƒœ', ''), Config.Status.PENDING_INTERVIEWER)

            # InterviewRequest ê°ì²´ ìƒì„±
            request = InterviewRequest(
                id=normalize_request_id(record['ìš”ì²­ID']),  # ì •ê·œí™” ì ìš©
                interviewer_id=record['ë©´ì ‘ê´€ID'],
                candidate_email=record['ë©´ì ‘ìì´ë©”ì¼'],
                candidate_name=record['ë©´ì ‘ìëª…'],
                position_name=record['ê³µê³ ëª…'],
                detailed_position_name=record.get('ìƒì„¸ê³µê³ ëª…', ''),
                status=status,
                created_at=created_at,
                updated_at=datetime.now(),
                available_slots=available_slots,
                preferred_datetime_slots=preferred_slots,
                selected_slot=selected_slot,
                candidate_note=record.get('ë©´ì ‘ììš”ì²­ì‚¬í•­', ''),
                candidate_phone=record.get('ë©´ì ‘ìì „í™”ë²ˆí˜¸', '')
            )

            logger.info(f"âœ… êµ¬ê¸€ì‹œíŠ¸ ë ˆì½”ë“œ ë³€í™˜ ì™„ë£Œ: {request.id}")
            return request

        except Exception as e:
            logger.error(f"âŒ ì‹œíŠ¸ ë ˆì½”ë“œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def get_all_requests(self) -> List[InterviewRequest]:
        """ëª¨ë“  ë©´ì ‘ ìš”ì²­ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("SELECT id FROM interview_requests ORDER BY created_at DESC")
                request_ids = [row[0] for row in cursor.fetchall()]
            
            requests = []
            for req_id in request_ids:
                request = self.get_interview_request(req_id)
                if request:
                    requests.append(request)
            
            return requests
        except Exception as e:
            logger.error(f"ì „ì²´ ìš”ì²­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    @retry_on_failure(max_retries=3, delay=1)
    def save_to_google_sheet(self, request: InterviewRequest):
        """êµ¬ê¸€ ì‹œíŠ¸ì— ìƒˆë¡œìš´ ìš”ì²­ ì €ì¥"""
        if not self.sheet:
            logger.warning("êµ¬ê¸€ ì‹œíŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            from utils import get_employee_info
            interviewer_info = get_employee_info(request.interviewer_id)
            
            row_data = self._prepare_sheet_row_data(request, interviewer_info)
            self.sheet.append_row(row_data)
            
            row_num = len(self.sheet.get_all_values())
            self._apply_status_formatting(row_num, request.status)
            
            logger.info(f"êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ: {request.id[:8]}...")
            return True
            
        except Exception as e:
            logger.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    @retry_on_failure(max_retries=3, delay=1)

    def health_check(self) -> dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬ (ìºì‹œ ì •ë³´ í¬í•¨)"""
        status = {
            'database': False,
            'google_sheet': False,
            'cache_stats': self.get_cache_stats(),
            'last_check': datetime.now().isoformat()
        }
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("SELECT 1").fetchone()
            status['database'] = True
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        
        try:
            if self.sheet:
                self.sheet.row_values(1)
                status['google_sheet'] = True
        except Exception as e:
            logger.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì²´í¬ ì‹¤íŒ¨: {e}")
            status['google_sheet'] = False

        return status

    def update_google_sheet(self, request: InterviewRequest):
        """êµ¬ê¸€ ì‹œíŠ¸ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        if not self.sheet:
            logger.warning("êµ¬ê¸€ ì‹œíŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            row_index = self._find_request_row(request.id)
            
            if row_index:
                # âœ… ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
                logger.info(f"ğŸ“ ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸: {row_index}ë²ˆ í–‰")
                updates = self._prepare_batch_updates(request, row_index)
                if updates:
                    self.sheet.batch_update(updates)
                    
                self._apply_status_formatting(row_index, request.status)
                
                logger.info(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {request.id[:8]}...")
                return True
            else:
                # âœ… ìƒˆ í–‰ ì¶”ê°€
                logger.info(f"ğŸ“ ìƒˆ í–‰ ì¶”ê°€")
                return self.save_to_google_sheet(request)
                
        except Exception as e:
            logger.error(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    def _find_request_row(self, request_id: str) -> Optional[int]:
        """ìš”ì²­ IDë¡œ í–‰ ë²ˆí˜¸ ì°¾ê¸° - ì •ê·œí™” ì ìš©"""
        from utils import normalize_request_id
        
        try:
            clean_id = normalize_request_id(request_id)
            all_records = self.sheet.get_all_records()
            
            for i, record in enumerate(all_records):
                sheet_id = normalize_request_id(record.get('ìš”ì²­ID', ''))
                if sheet_id == clean_id:
                    return i + 2
            return None
        except Exception as e:
            logger.error(f"í–‰ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def _prepare_sheet_row_data(self, request: InterviewRequest, interviewer_info: dict = None) -> list:
        """ì‹œíŠ¸ í–‰ ë°ì´í„° ì¤€ë¹„"""
        from utils import normalize_request_id, get_employee_info
        
        # âœ… ID ì •ê·œí™” (êµ¬ê¸€ì‹œíŠ¸ì™€ DB ì¼ì¹˜)
        normalized_id = normalize_request_id(request.id)
        
        interviewer_ids = [id.strip() for id in request.interviewer_id.split(',')]
        interviewer_names = []
        interviewer_departments = []
        
        for interviewer_id in interviewer_ids:
            info = get_employee_info(interviewer_id)
            interviewer_names.append(info.get('name', interviewer_id))
            interviewer_departments.append(info.get('department', 'ë¯¸í™•ì¸'))
        
        interviewer_id_str = ", ".join(interviewer_ids)
        interviewer_name_str = ", ".join(interviewer_names)
        interviewer_dept_str = ", ".join(set(interviewer_departments))
        
        preferred_datetime_str = " | ".join(request.preferred_datetime_slots) if request.preferred_datetime_slots else ""
        
        proposed_slots_str = ""
        if request.available_slots:
            proposed_slots_str = " | ".join([
                f"{slot.date} {slot.time}({slot.duration}ë¶„)" 
                for slot in request.available_slots
            ])
        
        confirmed_datetime = ""
        if request.selected_slot:
            confirmed_datetime = f"{request.selected_slot.date} {request.selected_slot.time}({request.selected_slot.duration}ë¶„)"
        
        processing_time = ""
        if request.updated_at and request.status == Config.Status.CONFIRMED:
            time_diff = request.updated_at - request.created_at
            hours = int(time_diff.total_seconds() // 3600)
            processing_time = f"{hours}ì‹œê°„" if hours > 0 else "1ì‹œê°„ ë¯¸ë§Œ"
        
        status_changed_at = request.updated_at.strftime('%Y-%m-%d %H:%M') if request.updated_at else request.created_at.strftime('%Y-%m-%d %H:%M')
        
        remarks = f"ë‹´ë‹¹ë¶€ì„œ: {interviewer_dept_str}" if len(interviewer_ids) > 1 else ""
        
        return [
            normalized_id,  # âœ… ì •ê·œí™”ëœ ID ì‚¬ìš©
            request.created_at.strftime('%Y-%m-%d %H:%M'),
            request.position_name,
            getattr(request, 'detailed_position_name', ''),
            interviewer_id_str,
            interviewer_name_str,
            request.candidate_name,
            request.candidate_email,
            getattr(request, 'candidate_phone', ''),
            request.status,
            status_changed_at,
            preferred_datetime_str,
            proposed_slots_str,
            confirmed_datetime,
            request.candidate_note or "",
            datetime.now().strftime('%Y-%m-%d %H:%M'),
            processing_time,
            remarks
        ]
    
    def _prepare_batch_updates(self, request: InterviewRequest, row_index: int) -> list:
        """ë°°ì¹˜ ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        try:
            from utils import get_employee_info
            
            interviewer_ids = [id.strip() for id in request.interviewer_id.split(',')]
            interviewer_names = []
            
            for interviewer_id in interviewer_ids:
                info = get_employee_info(interviewer_id)
                interviewer_names.append(info.get('name', interviewer_id))
            
            interviewer_name_str = ", ".join(interviewer_names)
            
            confirmed_datetime = ""
            if request.selected_slot:
                confirmed_datetime = f"{request.selected_slot.date} {request.selected_slot.time}({request.selected_slot.duration}ë¶„)"
            
            proposed_slots_str = ""
            if request.available_slots:
                proposed_slots_str = " | ".join([
                    f"{slot.date} {slot.time}({slot.duration}ë¶„)" 
                    for slot in request.available_slots
                ])
            
            preferred_datetime_str = ""
            if request.preferred_datetime_slots:
                preferred_datetime_str = " | ".join(request.preferred_datetime_slots)
            
            processing_time = ""
            if request.updated_at and request.status == Config.Status.CONFIRMED:
                time_diff = request.updated_at - request.created_at
                hours = int(time_diff.total_seconds() // 3600)
                processing_time = f"{hours}ì‹œê°„" if hours > 0 else "1ì‹œê°„ ë¯¸ë§Œ"

            detailed_name = getattr(request, 'detailed_position_name', '')
            phone = getattr(request, 'candidate_phone', '')

            # âœ… ìƒì„¸ê³µê³ ëª…ê³¼ ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
            logger.info(f"ğŸ“ ë°°ì¹˜ ì—…ë°ì´íŠ¸ - detailed_position_name: '{detailed_name}'")
            logger.info(f"ğŸ“ ë°°ì¹˜ ì—…ë°ì´íŠ¸ - candidate_phone: '{phone}'") 
            
            updates = [
                {'range': f'D{row_index}', 'values': [[detailed_name]]},  # Dì—´: ìƒì„¸ê³µê³ ëª…
                {'range': f'F{row_index}', 'values': [[interviewer_name_str]]},  # Fì—´: ë©´ì ‘ê´€ì´ë¦„
                {'range': f'I{row_index}', 'values': [[phone]]},  # Iì—´: ë©´ì ‘ìì „í™”ë²ˆí˜¸
                {'range': f'J{row_index}', 'values': [[request.status]]},  # Jì—´: ìƒíƒœ
                {'range': f'K{row_index}', 'values': [[request.updated_at.strftime('%Y-%m-%d %H:%M') if request.updated_at else ""]]},  # Kì—´: ìƒíƒœë³€ê²½ì¼ì‹œ
                {'range': f'L{row_index}', 'values': [[preferred_datetime_str]]},  # âœ… Lì—´: ì¸ì‚¬íŒ€ì œì•ˆì¼ì‹œ
                {'range': f'M{row_index}', 'values': [[proposed_slots_str]]},  # âœ… Mì—´: ë©´ì ‘ê´€í™•ì •ì¼ì‹œ
                {'range': f'N{row_index}', 'values': [[confirmed_datetime]]},  # âœ… Nì—´: ë©´ì ‘ìí™•ì •ì¼ì‹œ
                {'range': f'O{row_index}', 'values': [[request.candidate_note or ""]]},  # Oì—´: ë©´ì ‘ììš”ì²­ì‚¬í•­
                {'range': f'P{row_index}', 'values': [[datetime.now().strftime('%Y-%m-%d %H:%M')]]},  # Pì—´: ë§ˆì§€ë§‰ì—…ë°ì´íŠ¸
                {'range': f'Q{row_index}', 'values': [[processing_time]]},  # Qì—´: ì²˜ë¦¬ì†Œìš”ì‹œê°„
            ]
            
            return updates
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return []

    
    def _apply_status_formatting(self, row_index: int, status: str):
        """ìƒíƒœë³„ í–‰ ìƒ‰ìƒ ì ìš©"""
        try:
            color_map = {
                Config.Status.PENDING_INTERVIEWER: {'red': 1.0, 'green': 0.9, 'blue': 0.8},
                Config.Status.PENDING_CANDIDATE: {'red': 0.8, 'green': 0.9, 'blue': 1.0},
                Config.Status.CANDIDATE_EMAIL_SENT: {'red': 0.9, 'green': 0.85, 'blue': 1.0},    # âœ… ì—°ë³´ë¼ìƒ‰ (ìƒˆë¡œ ì¶”ê°€)
                Config.Status.CONFIRMED: {'red': 0.8, 'green': 1.0, 'blue': 0.8},
                Config.Status.PENDING_CONFIRMATION: {'red': 1.0, 'green': 1.0, 'blue': 0.8},
                Config.Status.CANCELLED: {'red': 0.9, 'green': 0.9, 'blue': 0.9},
            }
            
            color = color_map.get(status)
            if color:
                self.sheet.format(f'{row_index}:{row_index}', {
                    'backgroundColor': color
                })
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ì ìš© ì‹¤íŒ¨: {e}")
    
    def force_refresh(self):
        """ê°•ì œ ìƒˆë¡œê³ ì¹¨"""
        try:
            if self.gc and Config.GOOGLE_SHEET_ID:
                self.sheet = self.gc.open_by_key(Config.GOOGLE_SHEET_ID).sheet1
                logger.info("êµ¬ê¸€ ì‹œíŠ¸ ê°•ì œ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
                
                if hasattr(st, 'cache_data'):
                    st.cache_data.clear()
            else:
                logger.warning("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì´ ì—†ì–´ ìƒˆë¡œê³ ì¹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ê°•ì œ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}")
    
    def get_all_requests_realtime(self):
        """ì‹¤ì‹œê°„ ìš”ì²­ ì¡°íšŒ"""
        self.force_refresh()
        return self.get_all_requests()
    
    def get_statistics(self) -> dict:
        """í†µê³„ ë°ì´í„° ì¡°íšŒ"""
        try:
            requests = self.get_all_requests()
            
            stats = {
                'total': len(requests),
                'pending_interviewer': 0,
                'pending_candidate': 0,
                'pending_confirmation': 0,
                'confirmed': 0,
                'cancelled': 0,
                'avg_processing_time': 0
            }
            
            processing_times = []
            
            for req in requests:
                if req.status == Config.Status.PENDING_INTERVIEWER:
                    stats['pending_interviewer'] += 1
                elif req.status == Config.Status.PENDING_CANDIDATE:
                    stats['pending_candidate'] += 1
                elif req.status == Config.Status.PENDING_CONFIRMATION:
                    stats['pending_confirmation'] += 1
                elif req.status == Config.Status.CONFIRMED:
                    stats['confirmed'] += 1
                    if req.updated_at:
                        time_diff = req.updated_at - req.created_at
                        processing_times.append(time_diff.total_seconds() / 3600)
                elif req.status == Config.Status.CANCELLED:
                    stats['cancelled'] += 1
            
            if processing_times:
                stats['avg_processing_time'] = sum(processing_times) / len(processing_times)
            
            return stats
            
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'total': 0, 'pending_interviewer': 0, 'pending_candidate': 0,
                'pending_confirmation': 0, 'confirmed': 0, 'cancelled': 0,
                'avg_processing_time': 0
            }
    
    def health_check(self) -> dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        status = {
            'database': False,
            'google_sheet': False,
            'last_check': datetime.now().isoformat()
        }
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("SELECT 1").fetchone()
            status['database'] = True
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        
        try:
            if self.sheet:
                self.sheet.row_values(1)
                status['google_sheet'] = True
        except Exception as e:
            logger.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì²´í¬ ì‹¤íŒ¨: {e}")
            status['google_sheet'] = False  # â—ë°˜í™˜ì€ ê³„ì†ë¨

        return status
    
    def update_request_status_after_email(self, request_id: str, new_status: str = None) -> bool:
        """
        ë©´ì ‘ì ë©”ì¼ ë°œì†¡ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸
        
        Args:
            request_id: ìš”ì²­ ID
            new_status: ìƒˆë¡œìš´ ìƒíƒœ (ê¸°ë³¸ê°’: "ë©´ì ‘ì_ë©”ì¼ë°œì†¡")
        
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            from utils import normalize_request_id
            clean_id = normalize_request_id(request_id)
            
            # ê¸°ë³¸ ìƒíƒœ ì„¤ì •
            if new_status is None:
                new_status = Config.Status.CANDIDATE_EMAIL_SENT
            
            # 1. SQLite DB ì—…ë°ì´íŠ¸
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    UPDATE interview_requests 
                    SET status = ?, updated_at = ?
                    WHERE id = ?
                """, (new_status, datetime.now().isoformat(), clean_id))
            
            logger.info(f"âœ… DB ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {clean_id} â†’ {new_status}")
            
            # 2. êµ¬ê¸€ì‹œíŠ¸ ì—…ë°ì´íŠ¸
            if self.sheet:
                row_index = self._find_request_row(clean_id)
                
                if row_index:
                    # Jì—´: ìƒíƒœ, Kì—´: ìƒíƒœë³€ê²½ì¼ì‹œ
                    updates = [
                        {'range': f'J{row_index}', 'values': [[new_status]]},
                        {'range': f'K{row_index}', 'values': [[datetime.now().strftime('%Y-%m-%d %H:%M')]]}
                    ]
                    
                    self.sheet.batch_update(updates)
                    
                    # ìƒíƒœë³„ ìƒ‰ìƒ ì ìš©
                    self._apply_status_formatting(row_index, new_status)
                    
                    logger.info(f"âœ… êµ¬ê¸€ì‹œíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {clean_id}")
                else:
                    logger.warning(f"âš ï¸ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {clean_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def debug_request_search(self, request_id: str) -> dict:
        """ìš”ì²­ ID ê²€ìƒ‰ ë””ë²„ê¹… ì •ë³´"""
        from utils import normalize_request_id
        
        debug_info = {
            'original_id': request_id,
            'normalized_id': normalize_request_id(request_id),
            'sqlite_found': False,
            'sheet_found': False,
            'sqlite_total': 0,
            'sheet_total': 0,
            'similar_ids': []
        }
        
        try:
            clean_id = debug_info['normalized_id']
            
            # SQLite ê²€ìƒ‰
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("SELECT COUNT(*) FROM interview_requests")
                debug_info['sqlite_total'] = cursor.fetchone()[0]
                
                cursor = conn.execute("SELECT id FROM interview_requests WHERE id = ?", (clean_id,))
                debug_info['sqlite_found'] = cursor.fetchone() is not None
                
                # ìœ ì‚¬í•œ IDë“¤ ì°¾ê¸°
                cursor = conn.execute("SELECT id FROM interview_requests LIMIT 10")
                all_ids = [row[0] for row in cursor.fetchall()]
                debug_info['similar_ids'] = all_ids

            # êµ¬ê¸€ ì‹œíŠ¸ ê²€ìƒ‰
            if self.sheet:
                records = self.sheet.get_all_records()
                debug_info['sheet_total'] = len(records)
                
                for record in records:
                    sheet_id = normalize_request_id(record.get('ìš”ì²­ID', ''))
                    if sheet_id == clean_id:
                        debug_info['sheet_found'] = True
                        break
            
            return debug_info
            
        except Exception as e:
            debug_info['error'] = str(e)
            return debug_info

    def force_sync_specific_request(self, request_id: str) -> bool:
        """íŠ¹ì • ìš”ì²­ì˜ ê°•ì œ ë™ê¸°í™”"""
        try:
            from utils import normalize_request_id
            clean_id = normalize_request_id(request_id)
            
            if not self.sheet:
                logger.error("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì—†ìŒ")
                return False
            
            records = self.sheet.get_all_records()
            
            for record in records:
                sheet_id = normalize_request_id(record.get('ìš”ì²­ID', ''))
                if sheet_id == clean_id:
                    request = self._convert_sheet_record_to_request(record)
                    if request:
                        self.save_interview_request(request)
                        logger.info(f"âœ… ê°•ì œ ë™ê¸°í™” ì™„ë£Œ: {clean_id}")
                        return True
            
            logger.error(f"âŒ êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {clean_id}")
            return False
            
        except Exception as e:
            logger.error(f"âŒ ê°•ì œ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False











